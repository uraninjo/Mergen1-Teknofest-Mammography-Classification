{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom opencv-python-headless[app] nibabel matplotlib albumentations tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Zeynep Aygün\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as mpimg\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "\n",
    "height,width = (256,256) \n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "import albumentations as A\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "\n",
    "class LoadData_imonly(Dataset):\n",
    "    def __init__(self, images_path, classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.classes = classes\n",
    "        self.len = len(images_path)\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(height=height,width=width,p=1.0),\n",
    "            A.augmentations.transforms.CLAHE(clip_limit=(2.0,3.0), tile_grid_size=(8, 8), always_apply=False, p=0.5) \n",
    "        ])\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = pydicom.dcmread(self.images_path[idx]).pixel_array\n",
    "        img=np.invert(img)\n",
    "        img = ((img - img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "        \n",
    "        transformed = self.transform(image=img)\n",
    "        img = transformed[\"image\"]\n",
    "        img = np.array([img,img,img])\n",
    "\n",
    "        img=np.moveaxis(img,0,-1)\n",
    "        img = self.to_tensor(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Veri kümesini oluşturun\n",
    "# PATH=\"/media/uraninjo/7D72-19E7/teknofest/\"\n",
    "\n",
    "PATH=\"C:/Users/Zeynep Aygün/Desktop/ornek\"\n",
    "\n",
    "test_images_path=sorted(glob.glob(f'{PATH}/images/[Ertan,Zeynep]*/*/*.dcm'))  # Görüntü yollarının listesi\n",
    "\n",
    "classes = [0, 1, 2]  # Orijinal etiket değerleri\n",
    "print(len(test_images_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LoadData_imonly(test_images_path, classes)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=test_dataset[4]\n",
    "\n",
    "plt.imshow(np.transpose(imgs,(1,2,0)),cmap=\"inferno\")\n",
    "plt.imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (down_conv1): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv2): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv3): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv4): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (double_conv): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up_conv4): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv3): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv2): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv1): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)        \n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes=3, up_sample_mode='conv_transpose'):\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "# Get UNet model\n",
    "model = UNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class Temp:\n",
    "    _temp_img=None\n",
    "    _temp_mock=None\n",
    "    rel_vals=None\n",
    "\n",
    "def crop_and_mask_dcm_image(masks, idx):\n",
    "    real_img = pydicom.dcmread(test_images_path[idx]).pixel_array\n",
    "    real_img=np.invert(real_img)\n",
    "    real_img = ((real_img - real_img.min()) * (1/(real_img.max() - real_img.min()) * 255)).astype('uint8')\n",
    "    real_w,real_h=real_img.shape\n",
    "    mock_masks=cv2.resize(masks,(real_h,real_w), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    Temp._temp_mock=mock_masks\n",
    "    rslt = mock_masks* real_img\n",
    "\n",
    "    rows, cols = np.where(mock_masks!= 0)\n",
    "    y1, x1 = np.min(rows), np.min(cols)\n",
    "    y2, x2 = np.max(rows), np.max(cols)\n",
    "    # y1_rel,y2_rel=y1/256,y2/256\n",
    "    # x1_rel,x2_rel=x1/256,x2/256\n",
    "    # Temp.rel_vals=(y1_rel,y2_rel,x1_rel,x2_rel)\n",
    "    # print(y1,y2)\n",
    "    # print(x1,x2)\n",
    "\n",
    "\n",
    "    # Görüntüyü bounding box ile kırp\n",
    "    result = rslt[y1:y2+1, x1:x2+1]\n",
    "\n",
    "    # Maske dışındaki alanı siyah renge dök\n",
    "    result[mock_masks[y1:y2+1, x1:x2+1] == 0] = 0\n",
    "    Temp._temp_img=result\n",
    "\n",
    "    return imgs, rslt, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result folder already exists\n",
      "Folder already exists\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/çalışmalar_zeynep/ornek/images\\\\Ertan\\\\822670817\\\\LCC.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zeynep Aygün\\Desktop\\teknofest_github\\Mergen1-Teknofest\\zeynep\\after_segmentasyon.ipynb Cell 9\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m             \u001b[39m# plt.imshow(result,cmap=\"gray\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m             \u001b[39m# visualize_test_mask(predicted_masks[0], inputs[0])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m run_unet_test(\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/checkpoints_2/6_ValLoss0.5481_diceScore0.9260.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, test_dataset, \u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Zeynep Aygün\\Desktop\\teknofest_github\\Mergen1-Teknofest\\zeynep\\after_segmentasyon.ipynb Cell 9\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFolder already exists\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m plt\u001b[39m.\u001b[39;49mimsave(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/çalışmalar_zeynep/\u001b[39;49m\u001b[39m{\u001b[39;49;00m__hno\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m__tür\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m\"\u001b[39;49m,result,cmap\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgray\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m20\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/after_segmentasyon.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py:2200\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[0;32m   2198\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimsave)\n\u001b[0;32m   2199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimsave\u001b[39m(fname, arr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2200\u001b[0m     \u001b[39mreturn\u001b[39;00m matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimsave(fname, arr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1687\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mformat\u001b[39m)\n\u001b[0;32m   1688\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1689\u001b[0m image\u001b[39m.\u001b[39msave(fname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:2428\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2427\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2428\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw+b\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   2430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2431\u001b[0m     save_handler(\u001b[39mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/çalışmalar_zeynep/ornek/images\\\\Ertan\\\\822670817\\\\LCC.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def visualize_test_mask(output_np,masks):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    img=np.transpose(output_np,(1,2,0))\n",
    "    axs[0].imshow(img,cmap=\"gray\")\n",
    "    axs[0].set_title(\"Predicted mask\")\n",
    "    masks=np.transpose(masks.cpu(),(1,2,0))\n",
    "    axs[1].imshow(masks)\n",
    "    axs[1].set_title(\"Ground truth mask\")\n",
    "    plt.show()\n",
    "\n",
    "def run_unet_test(model_path, test_dataset, device):\n",
    "    try:\n",
    "        os.mkdir(f\"C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/çalışmalar_zeynep\")\n",
    "    except:\n",
    "        print(\"Result folder already exists\")\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    model = UNet()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            output_np = outputs.detach().cpu().numpy()\n",
    "            output_np = output_np - np.min(output_np)\n",
    "            output_np = output_np / np.max(output_np)\n",
    "            predicted_masks = np.around(output_np, decimals=0, out=None)\n",
    "\n",
    "            mask_1 = predicted_masks[0][1,:,:]\n",
    "            mask_2 = predicted_masks[0][2,:,:]\n",
    "            combined_mask = np.maximum(mask_1, mask_2)\n",
    "            \n",
    "            imgs, rslt, result = crop_and_mask_dcm_image(combined_mask,i)#inputs[0][0,:,:].cpu().numpy()\n",
    "            fname=test_images_path[i]\n",
    "            __tür=fname.split(\"/\")[-1].split(\".\")[0]\n",
    "            __hno=fname.split(\"/\")[-2]\n",
    "            \n",
    "            try:\n",
    "                os.mkdir(f\"C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/çalışmalar_zeynep/{__hno}\")\n",
    "            except:\n",
    "                print(\"Folder already exists\")\n",
    "            plt.imsave(f\"C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/çalışmalar_zeynep/{__hno}/{__tür}.png\",result,cmap=\"gray\")\n",
    "\n",
    "            if i==20:\n",
    "                break\n",
    "            # plt.imshow(result,cmap=\"gray\")\n",
    "            # visualize_test_mask(predicted_masks[0], inputs[0])\n",
    "\n",
    "run_unet_test(\"C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/checkpoints_2/6_ValLoss0.5481_diceScore0.9260.pt\", test_dataset, \"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
