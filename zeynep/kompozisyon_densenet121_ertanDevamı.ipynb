{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Zeynep Aygün\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve,confusion_matrix\n",
    "warnings.simplefilter('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "BATCH_SIZE=2\n",
    "EPOCH=40\n",
    "LEARNING_RATE=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 15000, 'val': 5398}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Maximum number of samples in the train set\n",
    "train_limit = 15000\n",
    "\n",
    "# Maximum number of samples in the val set\n",
    "val_limit = None\n",
    "\n",
    "# Create the original datasets and dataloaders\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((500,250)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((500,250)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = 'C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/data/ayrilmis'\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), data_transforms['val'])\n",
    "\n",
    "# Find the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "class_names=train_dataset.classes\n",
    "\n",
    "# Select 5000 images from each class\n",
    "selected_indices = []\n",
    "for i in range(num_classes):\n",
    "    class_indices = [idx for idx, label in enumerate(train_dataset.targets) if label == i]\n",
    "    class_indices = random.sample(class_indices, min(len(class_indices), 5000))\n",
    "    selected_indices.extend(class_indices)\n",
    "\n",
    "# Select the specified number of samples from the train set\n",
    "if train_limit is not None:\n",
    "    selected_indices = selected_indices[:train_limit]\n",
    "\n",
    "# Create new Subsets using the selected indices\n",
    "train_subset = Subset(train_dataset, selected_indices)\n",
    "val_subset = Subset(val_dataset, range(val_limit)) if val_limit is not None else val_dataset\n",
    "\n",
    "# Create new DataLoaders for the Subsets\n",
    "train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# Update the dataset_sizes dictionary\n",
    "dataset_sizes = {\n",
    "        'train': len(train_subset),\n",
    "        'val': len(val_subset)\n",
    "    }\n",
    "image_datasets = {\n",
    "        'train': train_subset,\n",
    "        'val': val_subset\n",
    "    }\n",
    "dataloaders={}\n",
    "dataloaders[\"train\"],dataloaders[\"val\"]=train_dataloader,val_dataloader\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(3,10))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, name, num_epochs=25):\n",
    "    \n",
    "    selected_indices = []\n",
    "    for i in range(num_classes):\n",
    "        class_indices = [idx for idx, label in enumerate(train_dataset.targets) if label == i]\n",
    "        class_indices = random.sample(class_indices, min(len(class_indices), 5000))\n",
    "        selected_indices.extend(class_indices)\n",
    "\n",
    "    # Select the specified number of samples from the train set\n",
    "    if train_limit is not None:\n",
    "        selected_indices = selected_indices[:train_limit]\n",
    "\n",
    "    # Create new Subsets using the selected indices\n",
    "    train_subset = Subset(train_dataset, selected_indices)\n",
    "    val_subset = Subset(val_dataset, range(val_limit)) if val_limit is not None else val_dataset\n",
    "\n",
    "    # Create new DataLoaders for the Subsets\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "    dataloaders[\"train\"],dataloaders[\"val\"]=train_dataloader,val_dataloader\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'modelPerformance/{name}')\n",
    "    except:\n",
    "        print('Dosya var')\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            #epochs\n",
    "            \n",
    "            epoch=int(len(image_datasets[phase])/BATCH_SIZE)\n",
    "            \n",
    "            for _ in tqdm(range(epoch)):\n",
    "                #Loading Data\n",
    "                \n",
    "                inputs, labels = next(iter(dataloaders[phase]))\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    labels = labels.to(device)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            \n",
    "            #epoch_auc= running_auc/(dataset_sizes[phase]-error)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            #AUC: {:.4f} , epoch_auc\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(        \n",
    "                phase, epoch_loss, epoch_acc))\n",
    "    \n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model,'modelPerformance/{}/best_model_{:.4f}acc_{}epochs.h5'.format(name,epoch_acc,num_epochs))\n",
    "\n",
    "                # Calculate and plot confusion matrix\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in dataloaders['val']:\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        y_true += labels.tolist()\n",
    "                        y_pred += preds.tolist()\n",
    "\n",
    "                cm = confusion_matrix(y_true, y_pred)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', \n",
    "                            xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel('Predicted labels')\n",
    "                plt.ylabel('True labels')\n",
    "                plt.title('Confusion matrix')\n",
    "                plt.show()\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    \n",
    "    with open(f'modelPerformance/{name}/'+sorted(os.listdir(f'modelPerformance/{name}/'))[-1], 'rb') as f:\n",
    "        buffer = io.BytesIO(f.read())\n",
    "    model=torch.load(buffer)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dosyalar var\n"
     ]
    }
   ],
   "source": [
    "# A dictionary of models.\n",
    "\n",
    "modeller={\n",
    "    'densenet169':models.densenet121(pretrained=True)\n",
    "}\n",
    "try:\n",
    "    os.mkdir('./modelPerformance')\n",
    "except:\n",
    "    print('Dosyalar var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dosya var\n",
      "Epoch 1/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:04<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1487 Acc: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:42<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0526 Acc: 0.6808\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:20<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0981 Acc: 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:08<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1573 Acc: 0.5741\n",
      "\n",
      "Epoch 3/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:25<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0814 Acc: 0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:03<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1044 Acc: 0.6323\n",
      "\n",
      "Epoch 4/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:46<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0863 Acc: 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:03<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0756 Acc: 0.6578\n",
      "\n",
      "Epoch 5/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:44<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0644 Acc: 0.6719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:17<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0795 Acc: 0.6536\n",
      "\n",
      "Epoch 6/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [22:35<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0854 Acc: 0.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:12<00:00, 20.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1003 Acc: 0.6349\n",
      "\n",
      "Epoch 7/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:10<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0825 Acc: 0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:18<00:00, 19.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0945 Acc: 0.6391\n",
      "\n",
      "Epoch 8/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:47<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0828 Acc: 0.6526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:19<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0850 Acc: 0.6512\n",
      "\n",
      "Epoch 9/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:03<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0864 Acc: 0.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:14<00:00, 20.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0892 Acc: 0.6452\n",
      "\n",
      "Epoch 10/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:58<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0738 Acc: 0.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:23<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0902 Acc: 0.6456\n",
      "\n",
      "Epoch 11/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:23<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0804 Acc: 0.6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:17<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0824 Acc: 0.6580\n",
      "\n",
      "Epoch 12/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:18<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0792 Acc: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:19<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0902 Acc: 0.6447\n",
      "\n",
      "Epoch 13/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:44<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0794 Acc: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:18<00:00, 19.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0865 Acc: 0.6501\n",
      "\n",
      "Epoch 14/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:16<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0833 Acc: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:03<00:00, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0775 Acc: 0.6589\n",
      "\n",
      "Epoch 15/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [20:32<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0792 Acc: 0.6576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:05<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0985 Acc: 0.6345\n",
      "\n",
      "Epoch 16/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [22:03<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0805 Acc: 0.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:42<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0834 Acc: 0.6514\n",
      "\n",
      "Epoch 17/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [23:13<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0899 Acc: 0.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:22<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0844 Acc: 0.6499\n",
      "\n",
      "Epoch 18/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [22:30<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0785 Acc: 0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:44<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0691 Acc: 0.6677\n",
      "\n",
      "Epoch 19/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [24:15<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0828 Acc: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:21<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0791 Acc: 0.6588\n",
      "\n",
      "Epoch 20/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:39<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0804 Acc: 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:24<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0976 Acc: 0.6341\n",
      "\n",
      "Epoch 21/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [21:16<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0826 Acc: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [02:05<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0645 Acc: 0.6701\n",
      "\n",
      "Epoch 22/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 3819/7500 [11:03<10:39,  5.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zeynep Aygün\\Desktop\\teknofest_github\\Mergen1-Teknofest\\zeynep\\kompozisyon_densenet121_ertanDevamı.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m exp_lr_scheduler \u001b[39m=\u001b[39m lr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer_ft, step_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# TRAINING\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                         num_epochs\u001b[39m=\u001b[39;49mEPOCH)\n",
      "\u001b[1;32mc:\\Users\\Zeynep Aygün\\Desktop\\teknofest_github\\Mergen1-Teknofest\\zeynep\\kompozisyon_densenet121_ertanDevamı.ipynb Cell 6\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# track history if only in train\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeynep%20Ayg%C3%BCn/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/kompozisyon_densenet121_ertanDevam%C4%B1.ipynb#W5sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\densenet.py:214\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 214\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m    215\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(features, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    216\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_avg_pool2d(out, (\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\densenet.py:123\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[1;34m(self, init_features)\u001b[0m\n\u001b[0;32m    121\u001b[0m features \u001b[39m=\u001b[39m [init_features]\n\u001b[0;32m    122\u001b[0m \u001b[39mfor\u001b[39;00m name, layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 123\u001b[0m     new_features \u001b[39m=\u001b[39m layer(features)\n\u001b[0;32m    124\u001b[0m     features\u001b[39m.\u001b[39mappend(new_features)\n\u001b[0;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(features, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\densenet.py:89\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     87\u001b[0m     bottleneck_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[0;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     bottleneck_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn_function(prev_features)\n\u001b[0;32m     91\u001b[0m new_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_rate \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\densenet.py:50\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbn_function\u001b[39m(\u001b[39mself\u001b[39m, inputs: List[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m     49\u001b[0m     concated_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(inputs, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m     bottleneck_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(concated_features)))  \u001b[39m# noqa: T484\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name,model in modeller.items(): \n",
    "    model_ft = model\n",
    "    model_ft=torch.load('C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/modelPerformance/best_model_0.7599acc_50epochs.h5')\n",
    "    \n",
    "    \"\"\"\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc =nn.Sequential(nn.Linear(num_ftrs, len(class_names)), nn.Softmax())\"\"\"\n",
    "\n",
    "    \"\"\" num_ftrs=model.heads[-1].in_features\n",
    "    model_ft.heads[-1]=nn.Sequential(nn.Linear(num_ftrs, len(class_names)), nn.Softmax())\"\"\"\n",
    "    \n",
    "    \"\"\"num_ftrs=model_ft.classifier.in_features\n",
    "    model_ft.classifier =nn.Sequential(nn.Linear(num_ftrs, len(class_names)), nn.Softmax())\"\"\"\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    #optimizer_ft = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.0001)\n",
    "\n",
    "    # TRAINING\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, name=name,\n",
    "                            num_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class get_metric():\n",
    "\n",
    "    def get_accuracy_graph(epochs, train_acc, val_acc):  # draw validation and train accuracy graphs\n",
    "        plt.plot(epochs, train_acc, color='#006BA4')\n",
    "        plt.plot(epochs, val_acc, color='#FF800E')\n",
    "        plt.grid(b=True, which='major', color='lightgray')\n",
    "        plt.grid(b=True, which='minor', color='lightgray')\n",
    "        plt.xticks(np.arange(0, 45, 5))\n",
    "        plt.yticks(np.arange(0.5, 1, 0.05))\n",
    "        plt.rcParams['figure.figsize'] = (8, 6)\n",
    "        plt.rcParams['figure.dpi'] = 600\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "        plt.legend(['Training Acc.', 'Validation Acc.'], loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    def get_loss_graph(epochs, train_losses, val_losses):  # draw validation and train loss graphs\n",
    "        matplotlib.rcdefaults()\n",
    "        plt.plot(epochs, train_losses, color='#006BA4')\n",
    "        plt.plot(epochs, val_losses, color='#FF800E')\n",
    "        plt.grid(b=True, which='major', color='lightgray')\n",
    "        plt.grid(b=True, which='minor', color='lightgray')\n",
    "        plt.xticks(np.arange(0, 45, 5))\n",
    "        plt.yticks(np.arange(0, 1.2, 0.2))\n",
    "        plt.rcParams['figure.dpi'] = 600\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss vs Validation Loss\")\n",
    "        plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    def test_label_predictions(model, device, test_loader):  # calculate outputs on test dataset for get metrics\n",
    "        model.eval()\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                model.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "        return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "    \n",
    "    def test_label_predictions_el2(model_0,model_1,model_2,model_3, device, test_loader):\n",
    "    \n",
    "        actuals = []\n",
    "        predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                outputs_0 = model_0(data).cuda().cpu()\n",
    "                _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "\n",
    "                outputs_1 = model_1(data)\n",
    "                _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "\n",
    "                outputs_2 = model_2(data)\n",
    "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
    "\n",
    "                outputs_3 = model_3(data)\n",
    "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
    "\n",
    "                final_pred=predicted_1\n",
    "                size=final_pred.size()\n",
    "\n",
    "                for i in range(0,(size[0])):   \n",
    "                    a=0              \n",
    "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
    "\n",
    "                        if predicted_1[i].item()==1:\n",
    "                            final_pred[i]=1\n",
    "\n",
    "                        if predicted_1[i].item()==0:\n",
    "                            final_pred[i]=0\n",
    "                        a+=1\n",
    "\n",
    "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1) :\n",
    "\n",
    "                        a+=1   \n",
    "                        if predicted_3[i].item()==0:\n",
    "                            final_pred[i]=0 \n",
    "\n",
    "                        if predicted_3[i].item()!=0:\n",
    "                            final_pred[i]=1                    \n",
    "                    if a==0:                   \n",
    "                        final_pred[i]=predicted_2[i] \n",
    "                actuals.extend(target.view_as(final_pred))\n",
    "                predictions.extend(final_pred)\n",
    "        return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "    def test_model(model ,device, test_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Correct Prediction: {:d}  Total Images: {:d}'.format(correct, total))\n",
    "        print('Test Accuracy = {:f}'.format(correct / total))\n",
    "    \n",
    "    def test_model_el2(model_0,model_1,model_2,model_3,device, test_loader):\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                outputs_0 = model_0(images)\n",
    "                _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "\n",
    "                outputs_1 = model_1(images)\n",
    "                _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "\n",
    "                outputs_2 = model_2(images)\n",
    "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
    "\n",
    "                outputs_3 = model_3(images)\n",
    "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
    "\n",
    "                final_pred=predicted_1\n",
    "                size=final_pred.size()\n",
    "\n",
    "                for i in range(0,(size[0])):   \n",
    "                    a=0              \n",
    "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
    "\n",
    "                        if predicted_1[i].item()==1:\n",
    "                            final_pred[i]=1\n",
    "\n",
    "                        if predicted_1[i].item()==0:\n",
    "                            final_pred[i]=0\n",
    "                        a+=1\n",
    "\n",
    "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1):\n",
    "\n",
    "                        a+=1\n",
    "\n",
    "                        if predicted_3[i].item()==0:\n",
    "                            final_pred[i]=0                        \n",
    "                        if predicted_3[i].item()!=0:\n",
    "                            final_pred[i]=1\n",
    "                    if a==0:                   \n",
    "                        final_pred[i]=predicted_2[i]\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (final_pred == labels).sum().item()\n",
    "        print('Correct Prediction: {:d}  Total Images: {:d}'.format(correct, total))\n",
    "        print('Test Accuracy = {:f}'.format(correct / total))\n",
    "\n",
    "    def get_classification_report(truth, predict):  # create classification report for each class with scikit-learn library\n",
    "        print('Classification Report :\\n', classification_report(truth, predict))\n",
    "\n",
    "    def get_confusion_matrix(actuals, predictions):  # create confusion matrix for each class with scikit-learn library\n",
    "        matplotlib.rcdefaults()\n",
    "        print('Confusion matrix:\\n',confusion_matrix(actuals, predictions))\n",
    "        cf_matrix=confusion_matrix(actuals, predictions)\n",
    "        sns.heatmap(cf_matrix, annot=True,fmt='g', cmap='Blues')\n",
    "\n",
    "    def get_cohen_kappa(actuals, predictions):  # get cohen kapa score for   determine model performance\n",
    "        cps = cohen_kappa_score(actuals, predictions)\n",
    "        print('Kappa Score of this model:\\n', cps)\n",
    "\n",
    "    def test_class_probabilities(model, device, test_loader, which_class):\n",
    "        \n",
    "        truths = []\n",
    "        probabilities = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data).cuda().cpu()\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                truths.extend(target.view_as(prediction) == which_class)\n",
    "                probabilities.extend(np.exp(output[:, which_class]))\n",
    "        return [i.item() for i in truths], [i.item() for i in probabilities]\n",
    "    def test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, test_loader, which_class):\n",
    "    \n",
    "        truths = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                outputs_0 = model_0(data)\n",
    "                _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "\n",
    "                outputs_1 = model_1(data)\n",
    "                _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "\n",
    "                outputs_2 = model_2(data)\n",
    "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
    "\n",
    "                outputs_3 = model_3(data)\n",
    "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
    "\n",
    "                final_pred=predicted_1\n",
    "                out=outputs_1\n",
    "                size=final_pred.size()\n",
    "\n",
    "                for i in range(0,(size[0])):   \n",
    "                    a=0              \n",
    "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
    "\n",
    "                        if predicted_1[i].item()==1:\n",
    "                            #final_pred[i]=1\n",
    "                            out[i]=outputs_1[i]\n",
    "\n",
    "                        if predicted_1[i].item()==0:\n",
    "                            final_pred[i]=0\n",
    "                            out[i]=outputs_1[i]\n",
    "                        a+=1\n",
    "\n",
    "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1):\n",
    "\n",
    "                        a+=1\n",
    "\n",
    "                        if predicted_3[i].item()==0:\n",
    "                            #final_pred[i]=0\n",
    "                            out[i]=outputs_3[i]\n",
    "\n",
    "                        if predicted_3[i].item()!=0:\n",
    "                            #final_pred[i]=1\n",
    "                            out[i]=outputs_3[i]\n",
    "                    if a==0:                   \n",
    "                        #final_pred[i]=predicted_2[i]\n",
    "                        out[i]=outputs_2[i]\n",
    "                prediction = out.argmax(dim=1, keepdim=True)\n",
    "                truths.extend(target.view_as(prediction) == which_class)\n",
    "                probabilities.extend(np.exp(out.cuda().cpu()[:, which_class]))\n",
    "        return [i.item() for i in truths], [i.item() for i in probabilities]\n",
    "    \n",
    "    def get_roc_curves_el2(model_0,model_1,model_2,model_3, device, data):  # draw Roc curves and calculate auc score for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, data, 0)\n",
    "        fpr[0], tpr[0], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[0] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, data, 1)\n",
    "        fpr[1], tpr[1], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[1] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        print(\"Auc Score For Each Class: \", roc_auc)\n",
    "\n",
    "        matplotlib.rcdefaults()\n",
    "        plt.figure()\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(2), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=1,\n",
    "            label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "            ''.format(i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_curves(model, device, data):  # draw Roc curves and calculate auc score for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 0)\n",
    "        fpr[0], tpr[0], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[0] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 1)\n",
    "        fpr[1], tpr[1], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[1] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 2)\n",
    "        fpr[2], tpr[2], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[2] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 3)\n",
    "        fpr[3], tpr[3], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[3] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        print(\"Auc Score For Each Class: \", roc_auc)\n",
    "\n",
    "        matplotlib.rcdefaults()\n",
    "        plt.figure()\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(2), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=1,\n",
    "                label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                    ''.format(i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve,confusion_matrix,precision_score,recall_score\n",
    "print('\\n'+'densenet169'+'\\n-----------------')  \n",
    "model_ft=torch.load('C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/modelPerformance/densenet169/best_model_0.5296acc_20epochs.h5')\n",
    "phase='val'\n",
    "actuals, predictions = get_metric.test_label_predictions(model_ft, device, dataloaders[phase])\n",
    "f1=f1_score(predictions,actuals,average=None)\n",
    "recall=recall_score(actuals,predictions,average=None)\n",
    "precision=precision_score(actuals,predictions,average=None)\n",
    "print(f'F1 Score: {f1[0]} {f1[1]} {f1[2]} {f1[3]}')\n",
    "print(f'Recall: {recall[0]} {recall[1]} {recall[2]} {recall[3]} ')\n",
    "print(f'Precision: {precision[0]} {precision[1]} {precision[2]} {precision[3]}')\n",
    "print('\\n')\n",
    "get_metric.get_classification_report(actuals, predictions)\n",
    "get_metric.test_model(model_ft,device,dataloaders[phase])\n",
    "get_metric.get_cohen_kappa(actuals, predictions)\n",
    "print('\\n')\n",
    "get_metric.get_confusion_matrix(actuals, predictions)\n",
    "print('\\n')\n",
    "#get_metric.get_roc_curves(model_ft, device,  dataloaders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
