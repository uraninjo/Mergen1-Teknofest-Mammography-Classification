{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Zeynep Aygün\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 21596, 'val': 5398, 'test': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE=2\n",
    "EPOCH=20\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/data/ayrilmis'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                        data_transforms[x])\n",
    "                    for x in ['train', 'val','test']}\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True, num_workers=0),\n",
    "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True, num_workers=0),\n",
    "    'test': torch.utils.data.DataLoader(image_datasets['test'], batch_size=BATCH_SIZE,\n",
    "                                            shuffle=False, num_workers=0)\n",
    "                                            }\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(40,40))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, name, num_epochs=25):\n",
    "\n",
    "    #Creating a folder to save the model performance.\n",
    "    try:\n",
    "        os.mkdir(f'modelPerformance/{name}')\n",
    "    except:\n",
    "        print('Dosya var')\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            #epochs\n",
    "            \n",
    "            epoch=int(len(image_datasets[phase])/BATCH_SIZE)\n",
    "            \n",
    "            for _ in tqdm(range(epoch)):\n",
    "                #Loading Data\n",
    "                \n",
    "                inputs, labels = next(iter(dataloaders[phase]))\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    labels = labels.to(device)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            \n",
    "            #epoch_auc= running_auc/(dataset_sizes[phase]-error)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            #AUC: {:.4f} , epoch_auc\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(        \n",
    "                phase, epoch_loss, epoch_acc))\n",
    "    \n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model,'modelPerformance/{}/best_model_{:.4f}acc_{}epochs.h5'.format(name,epoch_acc,num_epochs))\n",
    "\n",
    "                train_losses = []\n",
    "                valid_losses = []\n",
    "            \n",
    "        print()\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    \n",
    "    with open(f'modelPerformance/{name}/'+sorted(os.listdir(f'modelPerformance/{name}/'))[-1], 'rb') as f:\n",
    "        buffer = io.BytesIO(f.read())\n",
    "    model=torch.load(buffer)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dosyalar var\n"
     ]
    }
   ],
   "source": [
    "# A dictionary of models.\n",
    "\n",
    "modeller={\n",
    "    'resnet50':models.resnet50(pretrained=True)\n",
    "}\n",
    "try:\n",
    "    os.mkdir('./modelPerformance')\n",
    "except:\n",
    "    print('Dosyalar var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.resnet50(pretrained=True).fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [22:07<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.2444 Acc: 0.4882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:04<00:00, 41.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1223 Acc: 0.6162\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [11:03<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1309 Acc: 0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:06<00:00, 40.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1149 Acc: 0.6215\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [11:28<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0937 Acc: 0.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:11<00:00, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0778 Acc: 0.6608\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:43<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0771 Acc: 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:03<00:00, 42.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0673 Acc: 0.6712\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:55<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0765 Acc: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:03<00:00, 42.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0816 Acc: 0.6541\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:13<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0809 Acc: 0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:03<00:00, 42.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0905 Acc: 0.6449\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:34<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0728 Acc: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:20<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0930 Acc: 0.6419\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [11:07<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0830 Acc: 0.6566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:04<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0877 Acc: 0.6484\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:43<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0749 Acc: 0.6642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:03<00:00, 42.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0865 Acc: 0.6506\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:35<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0742 Acc: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [00:57<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0701 Acc: 0.6682\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:03<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0771 Acc: 0.6624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:25<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0930 Acc: 0.6451\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:32<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0694 Acc: 0.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:02<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0836 Acc: 0.6560\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:02<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0717 Acc: 0.6670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:08<00:00, 39.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0960 Acc: 0.6408\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [10:17<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0696 Acc: 0.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:05<00:00, 41.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0828 Acc: 0.6523\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:22<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0768 Acc: 0.6624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:06<00:00, 40.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0877 Acc: 0.6514\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:18<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0715 Acc: 0.6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [00:57<00:00, 46.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0795 Acc: 0.6577\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:39<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0700 Acc: 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [00:57<00:00, 46.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0776 Acc: 0.6601\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:10<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0687 Acc: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [00:57<00:00, 47.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0889 Acc: 0.6476\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:18<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0742 Acc: 0.6658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [01:02<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0904 Acc: 0.6436\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10798/10798 [09:24<00:00, 19.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0692 Acc: 0.6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699/2699 [00:56<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0768 Acc: 0.6595\n",
      "\n",
      "Training complete in 237m 25s\n",
      "Best val Acc: 0.671175\n"
     ]
    }
   ],
   "source": [
    "for name,model in modeller.items(): \n",
    "    model_ft = model\n",
    "    #model_ft=torch.load('C:/Users/Zeynep Aygün/Desktop/TEKNOFEST/yen/modelPerformance/vit/best_model_0.7244acc_20epochs.h5')\n",
    "    \n",
    "    \"\"\"\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc =nn.Sequential(nn.Linear(num_ftrs, len(class_names)), nn.Softmax())\"\"\"\n",
    "\n",
    "    \"\"\" num_ftrs=model.heads[-1].in_features\n",
    "    model_ft.heads[-1]=nn.Sequential(nn.Linear(num_ftrs, len(class_names)), nn.Softmax())\"\"\"\n",
    "    \n",
    "    num_ftrs=model_ft.fc.in_features\n",
    "    model_ft.fc =nn.Sequential(nn.Linear(num_ftrs, len(class_names)), nn.Softmax())\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    #optimizer_ft = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.0001)\n",
    "\n",
    "    # TRAINING\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, name=name,\n",
    "                            num_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class get_metric():\n",
    "\n",
    "    def get_accuracy_graph(epochs, train_acc, val_acc):  # draw validation and train accuracy graphs\n",
    "        plt.plot(epochs, train_acc, color='#006BA4')\n",
    "        plt.plot(epochs, val_acc, color='#FF800E')\n",
    "        plt.grid(b=True, which='major', color='lightgray')\n",
    "        plt.grid(b=True, which='minor', color='lightgray')\n",
    "        plt.xticks(np.arange(0, 45, 5))\n",
    "        plt.yticks(np.arange(0.5, 1, 0.05))\n",
    "        plt.rcParams['figure.figsize'] = (8, 6)\n",
    "        plt.rcParams['figure.dpi'] = 600\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "        plt.legend(['Training Acc.', 'Validation Acc.'], loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    def get_loss_graph(epochs, train_losses, val_losses):  # draw validation and train loss graphs\n",
    "        matplotlib.rcdefaults()\n",
    "        plt.plot(epochs, train_losses, color='#006BA4')\n",
    "        plt.plot(epochs, val_losses, color='#FF800E')\n",
    "        plt.grid(b=True, which='major', color='lightgray')\n",
    "        plt.grid(b=True, which='minor', color='lightgray')\n",
    "        plt.xticks(np.arange(0, 45, 5))\n",
    "        plt.yticks(np.arange(0, 1.2, 0.2))\n",
    "        plt.rcParams['figure.dpi'] = 600\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss vs Validation Loss\")\n",
    "        plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    def test_label_predictions(model, device, test_loader):  # calculate outputs on test dataset for get metrics\n",
    "        model.eval()\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                model.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "        return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "    \n",
    "    def test_label_predictions_el2(model_0,model_1,model_2,model_3, device, test_loader):\n",
    "    \n",
    "        actuals = []\n",
    "        predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                outputs_0 = model_0(data).cuda().cpu()\n",
    "                _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "\n",
    "                outputs_1 = model_1(data)\n",
    "                _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "\n",
    "                outputs_2 = model_2(data)\n",
    "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
    "\n",
    "                outputs_3 = model_3(data)\n",
    "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
    "\n",
    "                final_pred=predicted_1\n",
    "                size=final_pred.size()\n",
    "\n",
    "                for i in range(0,(size[0])):   \n",
    "                    a=0              \n",
    "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
    "\n",
    "                        if predicted_1[i].item()==1:\n",
    "                            final_pred[i]=1\n",
    "\n",
    "                        if predicted_1[i].item()==0:\n",
    "                            final_pred[i]=0\n",
    "                        a+=1\n",
    "\n",
    "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1) :\n",
    "\n",
    "                        a+=1   \n",
    "                        if predicted_3[i].item()==0:\n",
    "                            final_pred[i]=0 \n",
    "\n",
    "                        if predicted_3[i].item()!=0:\n",
    "                            final_pred[i]=1                    \n",
    "                    if a==0:                   \n",
    "                        final_pred[i]=predicted_2[i] \n",
    "                actuals.extend(target.view_as(final_pred))\n",
    "                predictions.extend(final_pred)\n",
    "        return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "    def test_model(model ,device, test_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Correct Prediction: {:d}  Total Images: {:d}'.format(correct, total))\n",
    "        print('Test Accuracy = {:f}'.format(correct / total))\n",
    "    \n",
    "    def test_model_el2(model_0,model_1,model_2,model_3,device, test_loader):\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                outputs_0 = model_0(images)\n",
    "                _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "\n",
    "                outputs_1 = model_1(images)\n",
    "                _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "\n",
    "                outputs_2 = model_2(images)\n",
    "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
    "\n",
    "                outputs_3 = model_3(images)\n",
    "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
    "\n",
    "                final_pred=predicted_1\n",
    "                size=final_pred.size()\n",
    "\n",
    "                for i in range(0,(size[0])):   \n",
    "                    a=0              \n",
    "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
    "\n",
    "                        if predicted_1[i].item()==1:\n",
    "                            final_pred[i]=1\n",
    "\n",
    "                        if predicted_1[i].item()==0:\n",
    "                            final_pred[i]=0\n",
    "                        a+=1\n",
    "\n",
    "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1):\n",
    "\n",
    "                        a+=1\n",
    "\n",
    "                        if predicted_3[i].item()==0:\n",
    "                            final_pred[i]=0                        \n",
    "                        if predicted_3[i].item()!=0:\n",
    "                            final_pred[i]=1\n",
    "                    if a==0:                   \n",
    "                        final_pred[i]=predicted_2[i]\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (final_pred == labels).sum().item()\n",
    "        print('Correct Prediction: {:d}  Total Images: {:d}'.format(correct, total))\n",
    "        print('Test Accuracy = {:f}'.format(correct / total))\n",
    "\n",
    "    def get_classification_report(truth, predict):  # create classification report for each class with scikit-learn library\n",
    "        print('Classification Report :\\n', classification_report(truth, predict))\n",
    "\n",
    "    def get_confusion_matrix(actuals, predictions):  # create confusion matrix for each class with scikit-learn library\n",
    "        matplotlib.rcdefaults()\n",
    "        print('Confusion matrix:\\n',confusion_matrix(actuals, predictions))\n",
    "        cf_matrix=confusion_matrix(actuals, predictions)\n",
    "        sns.heatmap(cf_matrix, annot=True,fmt='g', cmap='Blues')\n",
    "\n",
    "    def get_cohen_kappa(actuals, predictions):  # get cohen kapa score for   determine model performance\n",
    "        cps = cohen_kappa_score(actuals, predictions)\n",
    "        print('Kappa Score of this model:\\n', cps)\n",
    "\n",
    "    def test_class_probabilities(model, device, test_loader, which_class):\n",
    "        \n",
    "        truths = []\n",
    "        probabilities = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data).cuda().cpu()\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                truths.extend(target.view_as(prediction) == which_class)\n",
    "                probabilities.extend(np.exp(output[:, which_class]))\n",
    "        return [i.item() for i in truths], [i.item() for i in probabilities]\n",
    "    def test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, test_loader, which_class):\n",
    "    \n",
    "        truths = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                outputs_0 = model_0(data)\n",
    "                _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "\n",
    "                outputs_1 = model_1(data)\n",
    "                _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "\n",
    "                outputs_2 = model_2(data)\n",
    "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
    "\n",
    "                outputs_3 = model_3(data)\n",
    "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
    "\n",
    "                final_pred=predicted_1\n",
    "                out=outputs_1\n",
    "                size=final_pred.size()\n",
    "\n",
    "                for i in range(0,(size[0])):   \n",
    "                    a=0              \n",
    "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
    "\n",
    "                        if predicted_1[i].item()==1:\n",
    "                            #final_pred[i]=1\n",
    "                            out[i]=outputs_1[i]\n",
    "\n",
    "                        if predicted_1[i].item()==0:\n",
    "                            final_pred[i]=0\n",
    "                            out[i]=outputs_1[i]\n",
    "                        a+=1\n",
    "\n",
    "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1):\n",
    "\n",
    "                        a+=1\n",
    "\n",
    "                        if predicted_3[i].item()==0:\n",
    "                            #final_pred[i]=0\n",
    "                            out[i]=outputs_3[i]\n",
    "\n",
    "                        if predicted_3[i].item()!=0:\n",
    "                            #final_pred[i]=1\n",
    "                            out[i]=outputs_3[i]\n",
    "                    if a==0:                   \n",
    "                        #final_pred[i]=predicted_2[i]\n",
    "                        out[i]=outputs_2[i]\n",
    "                prediction = out.argmax(dim=1, keepdim=True)\n",
    "                truths.extend(target.view_as(prediction) == which_class)\n",
    "                probabilities.extend(np.exp(out.cuda().cpu()[:, which_class]))\n",
    "        return [i.item() for i in truths], [i.item() for i in probabilities]\n",
    "    \n",
    "    def get_roc_curves_el2(model_0,model_1,model_2,model_3, device, data):  # draw Roc curves and calculate auc score for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, data, 0)\n",
    "        fpr[0], tpr[0], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[0] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, data, 1)\n",
    "        fpr[1], tpr[1], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[1] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        print(\"Auc Score For Each Class: \", roc_auc)\n",
    "\n",
    "        matplotlib.rcdefaults()\n",
    "        plt.figure()\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(2), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=1,\n",
    "            label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "            ''.format(i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_curves(model, device, data):  # draw Roc curves and calculate auc score for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 0)\n",
    "        fpr[0], tpr[0], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[0] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 1)\n",
    "        fpr[1], tpr[1], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[1] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 2)\n",
    "        fpr[2], tpr[2], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[2] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 3)\n",
    "        fpr[3], tpr[3], _ = roc_curve(actuals, class_probabilities)\n",
    "        roc_auc[3] = roc_auc_score(actuals, class_probabilities)\n",
    "\n",
    "        print(\"Auc Score For Each Class: \", roc_auc)\n",
    "\n",
    "        matplotlib.rcdefaults()\n",
    "        plt.figure()\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(2), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=1,\n",
    "                label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                    ''.format(i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "swin_v2_s\n",
      "-----------------\n",
      "F1 Score: 0.0 0.7224540901502504 0.6845675522894291\n",
      "Recall: 0.0 0.9034446764091858 0.6242268041237113 \n",
      "Precision: 0.0 0.6018776077885952 0.7578222778473092\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       596\n",
      "           1       0.60      0.90      0.72      1916\n",
      "           2       0.76      0.62      0.68      1940\n",
      "           3       0.72      0.70      0.71       946\n",
      "\n",
      "    accuracy                           0.67      5398\n",
      "   macro avg       0.52      0.56      0.53      5398\n",
      "weighted avg       0.61      0.67      0.63      5398\n",
      "\n",
      "Correct Prediction: 3605  Total Images: 5398\n",
      "Test Accuracy = 0.667840\n",
      "Kappa Score of this model:\n",
      " 0.5075440002230616\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[   0  584    1   11]\n",
      " [   0 1731  138   47]\n",
      " [   0  526 1211  203]\n",
      " [   0   35  248  663]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve,confusion_matrix,precision_score,recall_score\n",
    "print('\\n'+'swin_v2_s'+'\\n-----------------')  \n",
    "model_ft=torch.load('C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/modelPerformance/resnet50/best_model_0.6712acc_20epochs.h5')\n",
    "phase='val'\n",
    "actuals, predictions = get_metric.test_label_predictions(model_ft, device, dataloaders[phase])\n",
    "f1=f1_score(predictions,actuals,average=None)\n",
    "recall=recall_score(actuals,predictions,average=None)\n",
    "precision=precision_score(actuals,predictions,average=None)\n",
    "print(f'F1 Score: {f1[0]} {f1[1]} {f1[2]}')\n",
    "print(f'Recall: {recall[0]} {recall[1]} {recall[2]} ')\n",
    "print(f'Precision: {precision[0]} {precision[1]} {precision[2]}')\n",
    "print('\\n')\n",
    "get_metric.get_classification_report(actuals, predictions)\n",
    "get_metric.test_model(model_ft,device,dataloaders[phase])\n",
    "get_metric.get_cohen_kappa(actuals, predictions)\n",
    "print('\\n')\n",
    "get_metric.get_confusion_matrix(actuals, predictions)\n",
    "print('\\n')\n",
    "#get_metric.get_roc_curves(model_ft, device,  dataloaders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "     -------------------------------------- 250.0/250.0 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\zeynep aygün\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/veribilgisi.xlsx\")\n",
    "\n",
    "\n",
    "df2 = pd.read_excel('C:/Users/Zeynep Aygün/Desktop/veribilgisi_ilk.xlsx')\n",
    "\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "\n",
    "df.to_excel('birlesik_dosya.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekrar eden öğeler:\n",
      " Empty DataFrame\n",
      "Columns: [HASTANO, BIRADS KATEGORİSİ, MEME KOMPOZİSYONU, KADRAN BİLGİSİ (SAĞ), KADRAN BİLGİSİ (SOL), Birads Skoru (EK BİLGİ OLARAK VERİLMİŞTİR, YARIŞMADA İSTENMEYECEKTİR)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/veribilgisi.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/veribilgisi_ilk.xlsx\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "duplicates = merged_df[merged_df.duplicated()]\n",
    "\n",
    "print(\"Tekrar eden öğeler:\\n\", duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekrar eden öğeler:\n",
      " Empty DataFrame\n",
      "Columns: [HASTANO, BIRADS KATEGORİSİ, MEME KOMPOZİSYONU, KADRAN BİLGİSİ (SAĞ), KADRAN BİLGİSİ (SOL), Birads Skoru (EK BİLGİ OLARAK VERİLMİŞTİR, YARIŞMADA İSTENMEYECEKTİR)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/deneme.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/veribilgisi_31_01_23.xlsx\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "duplicates = merged_df[merged_df.duplicated()]\n",
    "\n",
    "print(\"Tekrar eden öğeler:\\n\", duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/deneme.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/veribilgisi_31_01_23.xlsx\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "duplicates = merged_df[merged_df.duplicated(subset=['HASTANO'])]\n",
    "\n",
    "print(\"Tekrar eden öğeler:\\n\", duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIRADS 7954\n",
      "KOMPOZİSYON 7953\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/deneme.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/veribilgisi_31_01_23.xlsx\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "duplicates = merged_df[merged_df.duplicated(subset=['BIRADS KATEGORİSİ'])]['BIRADS KATEGORİSİ']\n",
    "duplicates2 = merged_df[merged_df.duplicated(subset=['MEME KOMPOZİSYONU'])]['MEME KOMPOZİSYONU']\n",
    "\n",
    "\n",
    "\n",
    "print(\"BIRADS\",len(duplicates))\n",
    "print(\"KOMPOZİSYON\",len(duplicates2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ortak değer sayısı: 243488\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/deneme.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/Zeynep Aygün/Desktop/okul/veribilgisi_31_01_23.xlsx\")\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on=[\"BIRADS KATEGORİSİ\", \"MEME KOMPOZİSYONU\"], how=\"inner\")\n",
    "\n",
    "print(\"Ortak değer sayısı:\", merged_df.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
