{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom opencv-python-headless[app] nibabel matplotlib albumentations tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeynep Aygün\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Zeynep Aygün\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as mpimg\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "\n",
    "height,width = (256,256) \n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "import albumentations as A\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "def mask_transform(mask, classes):\n",
    "    new_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "    for i, label in enumerate(classes):\n",
    "        new_mask[mask == label] = i\n",
    "    return new_mask\n",
    "\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self, images_path, masks_path, classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.classes = classes\n",
    "        self.len = len(images_path)\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(height=height,width=width,p=1.0),\n",
    "            A.augmentations.transforms.CLAHE(clip_limit=(2.0,3.0), tile_grid_size=(8, 8), always_apply=False, p=0.5) \n",
    "        ])\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = pydicom.dcmread(self.images_path[idx])\n",
    "        monochrome=img.PhotometricInterpretation\n",
    "        img=img.pixel_array\n",
    "        mask = nib.load(self.masks_path[idx])\n",
    "        mask=mask.get_fdata()\n",
    "        \n",
    "        \n",
    "        if 'Sinem' in self.images_path[idx] :\n",
    "            if 'LCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,1]\n",
    "            elif 'LMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,3]\n",
    "            elif 'RCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,0]\n",
    "            elif 'RMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,2]\n",
    "\n",
    "        elif 'Ertan' in self.images_path[idx]:\n",
    "            mask=mask[:,:,0]\n",
    "            \n",
    "        elif 'Zeynep' in self.images_path[idx]:\n",
    "            if 'LCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,0]\n",
    "            elif 'LMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,1]\n",
    "            elif 'RCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,2]\n",
    "            elif 'RMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,3]\n",
    "\n",
    "        mask=np.flip(mask)\n",
    "        mask=np.rot90(mask)\n",
    "        mask=np.fliplr(mask)\n",
    "\n",
    "        if monochrome=='MONOCHROME1':\n",
    "            img=np.invert(img)\n",
    "\n",
    "        img = ((img - img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "        \n",
    "        #img, mask = np.array(img), np.array(mask)\n",
    "        transformed = self.transform(image=img,mask=mask)\n",
    "        img = transformed['image']\n",
    "        mask = transformed['mask']\n",
    "        \n",
    "        #img = np.array([img,img,img])\n",
    "        #*****************************\n",
    "        mask_list=[]\n",
    "        temp_mask=mask.copy()\n",
    "        temp_mask[mask==1]=1\n",
    "        temp_mask[mask==2]=0\n",
    "        temp_mask[mask==3]=0\n",
    "        mask_list.append(temp_mask)\n",
    "\n",
    "        temp_mask=mask.copy()\n",
    "        temp_mask[mask==1]=0\n",
    "        temp_mask[mask==2]=1\n",
    "        temp_mask[mask==3]=1    #*1\n",
    "\n",
    "        mask_list.append(temp_mask)\n",
    "        \n",
    "        temp_mask=mask.copy()\n",
    "        temp_mask[mask==1]=0\n",
    "        temp_mask[mask==2]=0\n",
    "        temp_mask[mask==3]=0    #*0\n",
    "        mask_list.append(temp_mask)\n",
    "        \n",
    "        mask=np.array(mask_list)\n",
    "\n",
    "        img = np.array([img,img,img])\n",
    "\n",
    "        #********************************\n",
    "        img=np.moveaxis(img,0,-1)\n",
    "        mask=np.moveaxis(mask,0,-1)\n",
    "\n",
    "        img = self.to_tensor(img)\n",
    "\n",
    "        mask = self.to_tensor(mask)\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Veri kümesini oluşturun\n",
    "PATH=\"C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/data\"\n",
    "\n",
    "tr_images_path =sorted(glob.glob(f'{PATH}/images/[Ertan,Zeynep]*/*/*.dcm'))  # Görüntü yollarının listesi\n",
    "val_images_path =sorted(glob.glob(f'{PATH}/images/Sinem/*/*.dcm'))  # Görüntü yollarının listesi\n",
    "\n",
    "tr_masks_path=sorted(glob.glob(f'{PATH}/masks/[Ertan,Zeynep]*/*/*.nii.gz'))\n",
    "val_masks_path=sorted(glob.glob(f'{PATH}/masks/Sinem/*/*.nii.gz'))  # Maske yollarının listesi\n",
    "classes = [0, 1, 2]  # Orijinal etiket değerleri\n",
    "print(len(tr_images_path))\n",
    "print(len(tr_masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = LoadData(tr_images_path, tr_masks_path, classes)\n",
    "val_dataset = LoadData(val_images_path, val_masks_path, classes)\n",
    "\n",
    "# # Veri kümesini eğitim ve doğrulama alt kümelerine ayırma\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader oluşturma\n",
    "train_loader = DataLoader(tr_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,masks=tr_dataset[341]\n",
    "\n",
    "\n",
    "# img=np.invert(imgs)\n",
    "#plt.imshow(imgs,cmap=\"gray\")\n",
    "\n",
    "# plt.imshow(np.transpose(imgs,(1,2,0)),cmap=\"inferno\")\n",
    "\n",
    "plt.imshow(np.transpose(masks,(1,2,0))[:,:,2],cmap=\"gray\")\n",
    "plt.imshow\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(masks,(1,2,0))[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)        \n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes=3, up_sample_mode='conv_transpose'):\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "# Get UNet model\n",
    "model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def calculate_dice(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "\n",
    "def dice_loss(pred, target, epsilon=1e-7, use_sigmoid=True):\n",
    "    pred = pred.contiguous()\n",
    "    if use_sigmoid:\n",
    "        pred = torch.sigmoid(pred)\n",
    "    target = target.contiguous()\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + epsilon) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + epsilon)))\n",
    "    return loss.mean()\n",
    "\n",
    "def calculate_jaccard(y_true, y_pred):\n",
    "    # print(y_true.shape)\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred\n",
    "    return jaccard_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_image_mask(image, mask, pred_mask):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(mask.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap=\"gray\")\n",
    "    ax[1].set_title(\"True Mask\")\n",
    "    ax[2].imshow(np.dstack((pred_mask[0], pred_mask[1], pred_mask[2])), cmap=\"gray\")\n",
    "    ax[2].set_title(\"Predicted Mask\")\n",
    "    print(pred_mask.shape)\n",
    "    print(np.unique(pred_mask[0,:,:]))\n",
    "    print(np.unique(mask.cpu().numpy()))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def visualize_image_mask(image, mask, pred_mask):\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    ax[0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(mask.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap=\"gray\")\n",
    "    ax[1].set_title(\"True Mask\")\n",
    "    pred_mask1=np.array([pred_mask[0],pred_mask[0],pred_mask[0]])\n",
    "    pred_mask2=np.array([pred_mask[1],pred_mask[1],pred_mask[1]])\n",
    "    pred_mask3=np.array([pred_mask[2],pred_mask[2],pred_mask[2]])\n",
    "    ax[2].imshow(np.transpose(pred_mask1,(1,2,0)), cmap=\"gray\")\n",
    "    ax[2].set_title(\"Pektoral Predicted Mask\")\n",
    "    ax[3].imshow(np.transpose(pred_mask2,(1,2,0)), cmap=\"gray\")\n",
    "    ax[3].set_title(\"Meme Predicted Mask\")\n",
    "    ax[4].imshow(np.transpose(pred_mask3,(1,2,0)), cmap=\"gray\")\n",
    "    ax[4].set_title(\"Meme Ucu Predicted Mask\")\n",
    "    ax[5].imshow(np.transpose(pred_mask,(1,2,0)), cmap=\"gray\")\n",
    "    ax[5].set_title(\"All Predicted Mask\")\n",
    "\n",
    "    # print(pred_mask.shape)\n",
    "    # print(np.unique(pred_mask[0,:,:]))\n",
    "    # print(np.unique(mask.cpu().numpy()))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def validate_unet(model, val_loader, device, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    jaccard = 0.0\n",
    "    dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, masks) in enumerate(val_loader):\n",
    "            inputs, masks = inputs.cpu().to(device), masks.cpu().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            # print(outputs.shape)\n",
    "            \n",
    "            output_np=outputs.detach().cpu()\n",
    "            output_np=np.array(output_np)\n",
    "            output_np=output_np-np.min(output_np)\n",
    "            output_np=output_np/np.max(output_np)\n",
    "            predicted_masks=np.around(output_np, decimals=0, out=None)\n",
    "            # _, predicted_masks = torch.max(outputs, 1)\n",
    "            # jaccard += calculate_jaccard(masks[0], predicted_masks[0])\n",
    "            dice += calculate_dice(masks[0], predicted_masks[0])\n",
    "\n",
    "            # İlk örnek için görselleştirme\n",
    "            \n",
    "            if i == 1:\n",
    "                visualize_image_mask(inputs[0], masks[0], predicted_masks[0])\n",
    "            if i == 2:\n",
    "                visualize_image_mask(inputs[0], masks[0], predicted_masks[0])\n",
    "            # if i == 3:\n",
    "            #     visualize_image_mask(inputs[0], masks[0], predicted_masks[0])\n",
    "            # if i == 4:\n",
    "            #     visualize_image_mask(inputs[0], masks[0], predicted_masks[0])\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    jaccard /= len(val_loader)\n",
    "    dice /= len(val_loader)\n",
    "    return val_loss, jaccard, dice\n",
    "\n",
    "def train_unet(epochs, device):\n",
    "    try:\n",
    "        os.mkdir(\"./checkpoints_4\")\n",
    "    except:\n",
    "        print(\"Checkpoints directory already exists\")\n",
    "\n",
    "    model = UNet()\n",
    "    model=model.to(device)\n",
    "    # model.load_state_dict(torch.load(\"/home/uraninjo/Desktop/Çalışmalar/Mergen1-Teknofest/Murat/checkpoints3/8_ValLoss0.4248_diceScore0.9020.pt\"))\n",
    "    criterion = dice_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    train_losses = []\n",
    "\n",
    "    best_dice = float('inf')*(-1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # Eğitim\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, masks in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, masks = inputs.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Doğrulama\n",
    "        val_loss, jaccard, dice = validate_unet(model, val_loader, device, criterion)\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Dice Score: {dice:.4f}\")\n",
    "\n",
    "        # En iyi modeli kaydetme\n",
    "        if dice > best_dice:\n",
    "            best_dice = dice\n",
    "            torch.save(model.state_dict(), f\"./checkpoints_4/{epoch}_ValLoss{val_loss:.4f}_diceScore{dice:.4f}.pt\")\n",
    "\n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_model = train_unet(epochs=50, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "def visualize_test_mask(output_np,masks):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    print(output_np.shape)\n",
    "    axs[0].imshow(np.transpose(output_np[0],(1,2,0)),cmap=\"gray\")\n",
    "    axs[0].set_title(\"Predicted mask\")\n",
    "    axs[1].imshow(np.transpose(masks.cpu()[0],(1,2,0)))\n",
    "    axs[1].set_title(\"Ground truth mask\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_unet(model, test_loader, device, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    jaccard = 0.0\n",
    "    dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, masks) in enumerate(test_loader):\n",
    "            inputs, masks = inputs.to(device), masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            output_np = outputs.detach().cpu().numpy()\n",
    "            output_np = output_np - np.min(output_np)\n",
    "            output_np = output_np / np.max(output_np)\n",
    "            predicted_masks = np.around(output_np, decimals=0, out=None)\n",
    "            \n",
    "            \n",
    "            visualize_image_mask(inputs[0], masks[0], predicted_masks[0])\n",
    "\n",
    "\n",
    "            dice += calculate_dice(masks[0], predicted_masks[0])\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    jaccard /= len(test_loader)\n",
    "    dice /= len(test_loader)\n",
    "    return test_loss, jaccard, dice\n",
    "\n",
    "def run_unet_test(model_path, test_dataset, device):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    model = UNet()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    criterion = dice_loss\n",
    "\n",
    "    test_loss, jaccard, dice = test_unet(model, test_loader, device, criterion)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Dice Score: {dice:.4f}\")\n",
    "\n",
    "run_unet_test(f\"C:/Users/Zeynep Aygün/Desktop/teknofest_github/Mergen1-Teknofest/zeynep/checkpoints_4/2_ValLoss0.5501_diceScore0.6804.pt\",val_dataset,device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
