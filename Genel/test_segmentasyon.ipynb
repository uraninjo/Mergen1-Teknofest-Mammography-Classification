{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentasyonun Nasıl Performans Gösterildiği Test Ediliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom opencv-python-headless[app] nibabel matplotlib albumentations tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as mpimg\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "\n",
    "height,width = (256,256) \n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "import albumentations as A\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "def mask_transform(mask, classes):\n",
    "    new_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "    for i, label in enumerate(classes):\n",
    "        new_mask[mask == label] = i\n",
    "    return new_mask\n",
    "\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self, images_path, masks_path, classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.classes = classes\n",
    "        self.len = len(images_path)\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(height=height,width=width,p=1.0),\n",
    "            A.augmentations.transforms.CLAHE(clip_limit=(2.0,3.0), tile_grid_size=(8, 8), always_apply=False, p=0.5) \n",
    "        ])\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        #self.normalize = Normalize(mean=[0.485], std=[0.229])\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = pydicom.dcmread(self.images_path[idx]).pixel_array\n",
    "        mask = nib.load(self.masks_path[idx])\n",
    "        mask=mask.get_fdata()\n",
    "        \n",
    "        \n",
    "        if 'Sinem' in self.images_path[idx] :\n",
    "            if 'LCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,1]\n",
    "            elif 'LMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,3]\n",
    "            elif 'RCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,0]\n",
    "            elif 'RMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,2]\n",
    "\n",
    "        elif 'Ertan' in self.images_path[idx]:\n",
    "            mask=mask[:,:,0]\n",
    "            \n",
    "        elif 'Zeynep' in self.images_path[idx]:\n",
    "            if 'LCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,0]\n",
    "            elif 'LMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,1]\n",
    "            elif 'RCC' in self.images_path[idx]:\n",
    "                mask=mask[:,:,2]\n",
    "            elif 'RMLO' in self.images_path[idx]:\n",
    "                mask=mask[:,:,3]\n",
    "\n",
    "        mask=np.flip(mask)\n",
    "        mask=np.rot90(mask)\n",
    "        mask=np.fliplr(mask)\n",
    "        # maske[maske==1]=0\n",
    "        #mask[mask==2]=0\n",
    "        #mask[mask==3]=0\n",
    "        \n",
    "        img=np.invert(img)\n",
    "\n",
    "        \n",
    "        #img=np.moveaxis(img,0,-1)\n",
    "\n",
    "        img = ((img - img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "        \n",
    "        #img, mask = np.array(img), np.array(mask)\n",
    "        transformed = self.transform(image=img,mask=mask)\n",
    "        img = transformed['image']\n",
    "        mask = transformed['mask']\n",
    "        \n",
    "        #img = np.array([img,img,img])\n",
    "        #*****************************\n",
    "        mask_list=[]\n",
    "        temp_mask=mask.copy()\n",
    "        temp_mask[mask==1]=1\n",
    "        temp_mask[mask==2]=0\n",
    "        temp_mask[mask==3]=0\n",
    "        mask_list.append(temp_mask)\n",
    "\n",
    "        temp_mask=mask.copy()\n",
    "        temp_mask[mask==1]=0\n",
    "        temp_mask[mask==2]=1\n",
    "        temp_mask[mask==3]=1\n",
    "\n",
    "        mask_list.append(temp_mask)\n",
    "        \n",
    "        temp_mask=mask.copy()\n",
    "        temp_mask[mask==1]=0\n",
    "        temp_mask[mask==2]=0\n",
    "        temp_mask[mask==3]=0\n",
    "        mask_list.append(temp_mask)\n",
    "        \n",
    "        mask=np.array(mask_list)\n",
    "\n",
    "        img = np.array([img,img,img])\n",
    "\n",
    "        #********************************\n",
    "        img=np.moveaxis(img,0,-1)\n",
    "        mask=np.moveaxis(mask,0,-1)\n",
    "\n",
    "        img = self.to_tensor(img)\n",
    "        mask = self.to_tensor(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Veri kümesini oluşturun\n",
    "# PATH=\"/home/uraninjo/Desktop/Çalışmalar/Mergen1-Teknofest/data\"\n",
    "PATH=\"/home/uraninjo/Desktop/Çalışmalar/Mergen1-Teknofest/test_verisi/Ertan\"\n",
    "\n",
    "test_images_path =sorted(glob.glob(f'{PATH}/images/*/*.dcm'))  # Görüntü yollarının listesi\n",
    "\n",
    "test_masks_path=sorted(glob.glob(f'{PATH}/masks/*/*.nii.gz'))  # Maske yollarının listesi\n",
    "classes = [0, 1, 2]  # Orijinal etiket değerleri\n",
    "print(len(test_images_path))\n",
    "print(len(test_masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LoadData(test_images_path, test_masks_path, classes)\n",
    "\n",
    "# # Veri kümesini eğitim ve doğrulama alt kümelerine ayırma\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader oluşturma\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,masks=test_dataset[41]\n",
    "\n",
    "\n",
    "# img=np.invert(imgs)\n",
    "#plt.imshow(imgs,cmap=\"gray\")\n",
    "\n",
    "plt.imshow(np.transpose(imgs,(1,2,0)),cmap=\"inferno\")\n",
    "\n",
    "plt.imshow(np.transpose(masks,(1,2,0))[:,:,2],cmap=\"inferno\",alpha=0.5)\n",
    "plt.imshow\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (down_conv1): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv2): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv3): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv4): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (double_conv): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up_conv4): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv3): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv2): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv1): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)        \n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes=3, up_sample_mode='conv_transpose'):\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "# Get UNet model\n",
    "model = UNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def calculate_dice(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "\n",
    "def dice_loss(pred, target, epsilon=1e-7, use_sigmoid=True):\n",
    "    pred = pred.contiguous()\n",
    "    if use_sigmoid:\n",
    "        pred = torch.sigmoid(pred)\n",
    "    target = target.contiguous()\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + epsilon) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + epsilon)))\n",
    "    return loss.mean()\n",
    "\n",
    "def calculate_jaccard(y_true, y_pred):\n",
    "    # print(y_true.shape)\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred\n",
    "    return jaccard_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_image_mask(image, mask, pred_mask):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(mask.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap=\"gray\")\n",
    "    ax[1].set_title(\"True Mask\")\n",
    "    ax[2].imshow(np.dstack((pred_mask[0], pred_mask[1], pred_mask[2])), cmap=\"gray\")\n",
    "    ax[2].set_title(\"Predicted Mask\")\n",
    "    print(pred_mask.shape)\n",
    "    print(np.unique(pred_mask[0,:,:]))\n",
    "    print(np.unique(mask.cpu().numpy()))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def visualize_image_mask(image, mask, pred_mask):\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    ax[0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(mask.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap=\"gray\")\n",
    "    ax[1].set_title(\"True Mask\")\n",
    "    pred_mask1=np.array([pred_mask[0],pred_mask[0],pred_mask[0]])\n",
    "    pred_mask2=np.array([pred_mask[1],pred_mask[1],pred_mask[1]])\n",
    "    pred_mask3=np.array([pred_mask[2],pred_mask[2],pred_mask[2]])\n",
    "    ax[2].imshow(np.transpose(pred_mask1,(1,2,0)), cmap=\"gray\")\n",
    "    ax[2].set_title(\"Pektoral Predicted Mask\")\n",
    "    ax[3].imshow(np.transpose(pred_mask2,(1,2,0)), cmap=\"gray\")\n",
    "    ax[3].set_title(\"Meme Predicted Mask\")\n",
    "    ax[4].imshow(np.transpose(pred_mask3,(1,2,0)), cmap=\"gray\")\n",
    "    ax[4].set_title(\"Meme Ucu Predicted Mask\")\n",
    "    ax[5].imshow(np.transpose(pred_mask,(1,2,0)), cmap=\"gray\")\n",
    "    ax[5].set_title(\"All Predicted Mask\")\n",
    "\n",
    "    # print(pred_mask.shape)\n",
    "    # print(np.unique(pred_mask[0,:,:]))\n",
    "    # print(np.unique(mask.cpu().numpy()))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "def visualize_test_mask(output_np,masks):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    print(output_np.shape)\n",
    "    axs[0].imshow(np.transpose(output_np[0],(1,2,0)),cmap=\"gray\")\n",
    "    axs[0].set_title(\"Predicted mask\")\n",
    "    axs[1].imshow(np.transpose(masks.cpu()[0],(1,2,0)))\n",
    "    axs[1].set_title(\"Ground truth mask\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_unet(model, test_loader, device, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    jaccard = 0.0\n",
    "    dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, masks) in enumerate(test_loader):\n",
    "            inputs, masks = inputs.to(device), masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            output_np = outputs.detach().cpu().numpy()\n",
    "            output_np = output_np - np.min(output_np)\n",
    "            output_np = output_np / np.max(output_np)\n",
    "            predicted_masks = np.around(output_np, decimals=0, out=None)\n",
    "            \n",
    "            \n",
    "            visualize_image_mask(inputs[0], masks[0], predicted_masks[0])\n",
    "\n",
    "\n",
    "            dice += calculate_dice(masks[0], predicted_masks[0])\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    jaccard /= len(test_loader)\n",
    "    dice /= len(test_loader)\n",
    "    return test_loss, jaccard, dice\n",
    "\n",
    "def run_unet_test(model_path, test_dataset, device):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    model = UNet()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    criterion = dice_loss\n",
    "\n",
    "    test_loss, jaccard, dice = test_unet(model, test_loader, device, criterion)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Dice Score: {dice:.4f}\")\n",
    "\n",
    "run_unet_test(f\"/home/uraninjo/Desktop/Çalışmalar/Mergen1-Teknofest/Murat/checkpoints3/Zeynep2Kanal_6_ValLoss0.5481_diceScore0.9260.pt\", test_dataset,device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_unet_test(f\"/home/uraninjo/Desktop/Çalışmalar/Mergen1-Teknofest/Murat/checkpoints3/Murat3Kanal_8_ValLoss0.4248_diceScore0.9020.pt\",val_dataset,device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
